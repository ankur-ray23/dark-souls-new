{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: Acid Surge\n",
      "Scraping: Black Flame\n",
      "Scraping: Chaos Fire Whip\n",
      "Scraping: Chaos Storm\n",
      "Scraping: Combustion\n",
      "Scraping: Fire Orb\n",
      "Scraping: Fire Surge\n",
      "Scraping: Fire Tempest\n",
      "Scraping: Fire Whip\n",
      "Scraping: Fireball\n",
      "Scraping: Firestorm\n",
      "Scraping: Flash Sweat\n",
      "Scraping: Great Chaos Fireball\n",
      "Scraping: Great Combustion\n",
      "Scraping: Great Fireball\n",
      "Scraping: Iron Flesh\n",
      "Scraping: Poison Mist\n",
      "Scraping: Power Within\n",
      "Scraping: Toxic Mist\n",
      "Scraping: Undead Rapport\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "BASE_URL = \"http://darksouls.wikidot.com\"\n",
    "SPELLS_URL = f\"{BASE_URL}/pyromancies\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def scrape_main_table():\n",
    "    response = requests.get(SPELLS_URL, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find(\"table\", class_=\"wiki-content-table\")\n",
    "    rows = table.find_all(\"tr\")[1:]\n",
    "\n",
    "    spells = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) < 7:\n",
    "            continue\n",
    "        name_tag = cols[1].find(\"a\")\n",
    "        name = name_tag.text.strip()\n",
    "        url = BASE_URL + name_tag['href']\n",
    "        spells.append({\n",
    "            \"name\": name,\n",
    "            \"url\": url,\n",
    "            \"uses\": cols[2].text.strip(),\n",
    "            \"slots\": cols[3].text.strip(),\n",
    "            \"short_description\": cols[4].text.strip(),\n",
    "            \"location\": cols[5].get_text(separator=\" / \", strip=True),\n",
    "            \"affinity\": cols[6].text.strip()\n",
    "        })\n",
    "    return spells\n",
    "\n",
    "def scrape_spell_details(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        content_div = soup.find(\"div\", {\"id\": \"page-content\"})\n",
    "\n",
    "        # In-Game Description\n",
    "        desc_header = content_div.find(\"h2\", string=lambda s: s and \"In-Game Description\" in s)\n",
    "        in_game_description = \"\"\n",
    "        if desc_header:\n",
    "            for sibling in desc_header.find_next_siblings():\n",
    "                if sibling.name == \"p\":\n",
    "                    in_game_description += sibling.get_text(separator=\" \", strip=True) + \" \"\n",
    "                elif sibling.name == \"h2\":\n",
    "                    break\n",
    "            in_game_description = in_game_description.strip()\n",
    "\n",
    "        # Availability\n",
    "        availability_header = content_div.find(\"h2\", string=lambda s: s and \"Availability\" in s)\n",
    "        availability = []\n",
    "        if availability_header:\n",
    "            ul = availability_header.find_next_sibling(\"ul\")\n",
    "            if ul:\n",
    "                availability = [li.get_text(separator=\" \", strip=True) for li in ul.find_all(\"li\", recursive=False)]\n",
    "\n",
    "        return {\n",
    "            \"in_game_description\": in_game_description,\n",
    "            \"availability\": availability\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return {\n",
    "            \"in_game_description\": None,\n",
    "            \"availability\": None\n",
    "        }\n",
    "\n",
    "# Run the full scraping process\n",
    "spells = scrape_main_table()\n",
    "\n",
    "for spell in spells:\n",
    "    print(f\"Scraping: {spell['name']}\")\n",
    "    details = scrape_spell_details(spell['url'])\n",
    "    spell[\"in_game_description\"] = details[\"in_game_description\"]\n",
    "    spell[\"availability\"] = details[\"availability\"]\n",
    "    time.sleep(1)  # polite delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"dark_souls_pyromancies_full.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(spells, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: Aural Decoy\n",
      "Scraping: Cast Light\n",
      "Scraping: Chameleon\n",
      "Scraping: Crystal Magic Weapon\n",
      "Scraping: Crystal Soul Spear\n",
      "Scraping: Dark Bead\n",
      "Scraping: Dark Fog\n",
      "Scraping: Dark Orb\n",
      "Scraping: Fall Control\n",
      "Scraping: Great Heavy Soul Arrow\n",
      "Scraping: Great Magic Weapon\n",
      "Scraping: Great Soul Arrow\n",
      "Scraping: Heavy Soul Arrow\n",
      "Scraping: Hidden Body\n",
      "Scraping: Hidden Weapon\n",
      "Scraping: Homing Crystal Soulmass\n",
      "Scraping: Homing Soulmass\n",
      "Scraping: Hush\n",
      "Scraping: Magic Shield\n",
      "Scraping: Magic Weapon\n",
      "Scraping: Pursuers\n",
      "Scraping: Remedy\n",
      "Scraping: Repair\n",
      "Scraping: Resist Curse\n",
      "Scraping: Soul Arrow\n",
      "Scraping: Soul Spear\n",
      "Scraping: Strong Magic Shield\n",
      "Scraping: White Dragon Breath\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "BASE_URL = \"http://darksouls.wikidot.com\"\n",
    "SPELLS_URL = f\"{BASE_URL}/sorceries\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def scrape_main_table():\n",
    "    response = requests.get(SPELLS_URL, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find(\"table\", class_=\"wiki-content-table\")\n",
    "    rows = table.find_all(\"tr\")[1:]\n",
    "\n",
    "    spells = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) < 8:\n",
    "            continue\n",
    "        name_tag = cols[1].find(\"a\")\n",
    "        name = name_tag.text.strip()\n",
    "        url = BASE_URL + name_tag['href']\n",
    "        spells.append({\n",
    "            \"name\": name,\n",
    "            \"url\": url,\n",
    "            \"uses\": cols[2].text.strip(),\n",
    "            \"slots\": cols[4].text.strip(),\n",
    "            \"short_description\": cols[5].text.strip(),\n",
    "            \"location\": cols[6].get_text(separator=\" / \", strip=True),\n",
    "            \"affinity\": cols[7].text.strip()\n",
    "        })\n",
    "    return spells\n",
    "\n",
    "def scrape_spell_details(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        content_div = soup.find(\"div\", {\"id\": \"page-content\"})\n",
    "\n",
    "        # In-Game Description\n",
    "        desc_header = content_div.find(\"h2\", string=lambda s: s and \"In-Game Description\" in s)\n",
    "        in_game_description = \"\"\n",
    "        if desc_header:\n",
    "            for sibling in desc_header.find_next_siblings():\n",
    "                if sibling.name == \"p\":\n",
    "                    in_game_description += sibling.get_text(separator=\" \", strip=True) + \" \"\n",
    "                elif sibling.name == \"h2\":\n",
    "                    break\n",
    "            in_game_description = in_game_description.strip()\n",
    "\n",
    "        # Availability\n",
    "        availability_header = content_div.find(\"h2\", string=lambda s: s and \"Availability\" in s)\n",
    "        availability = []\n",
    "        if availability_header:\n",
    "            ul = availability_header.find_next_sibling(\"ul\")\n",
    "            if ul:\n",
    "                availability = [li.get_text(separator=\" \", strip=True) for li in ul.find_all(\"li\", recursive=False)]\n",
    "\n",
    "        return {\n",
    "            \"in_game_description\": in_game_description,\n",
    "            \"availability\": availability\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return {\n",
    "            \"in_game_description\": None,\n",
    "            \"availability\": None\n",
    "        }\n",
    "\n",
    "# Run the full scraping process\n",
    "spells1 = scrape_main_table()\n",
    "\n",
    "for spell in spells1:\n",
    "    print(f\"Scraping: {spell['name']}\")\n",
    "    details = scrape_spell_details(spell['url'])\n",
    "    spell[\"in_game_description\"] = details[\"in_game_description\"]\n",
    "    spell[\"availability\"] = details[\"availability\"]\n",
    "    time.sleep(1)  # polite delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"dark_souls_sorceries_full.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(spells, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: Bountiful Sunlight\n",
      "Scraping: Darkmoon Blade\n",
      "Scraping: Emit Force\n",
      "Scraping: Force\n",
      "Scraping: Gravelord Greatsword Dance\n",
      "Scraping: Gravelord Sword Dance\n",
      "Scraping: Great Heal Excerpt\n",
      "Scraping: Great Heal\n",
      "Scraping: Great Lightning Spear\n",
      "Scraping: Great Magic Barrier\n",
      "Scraping: Heal\n",
      "Scraping: Homeward\n",
      "Scraping: Karmic Justice\n",
      "Scraping: Lightning Spear\n",
      "Scraping: Magic Barrier\n",
      "Scraping: Replenishment\n",
      "Scraping: Seek Guidance\n",
      "Scraping: Soothing Sunlight\n",
      "Scraping: Sunlight Blade\n",
      "Scraping: Sunlight Spear\n",
      "Scraping: Tranquil Walk of Peace\n",
      "Scraping: Vow of Silence\n",
      "Scraping: Wrath of the Gods\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "BASE_URL = \"http://darksouls.wikidot.com\"\n",
    "SPELLS_URL = f\"{BASE_URL}/miracles\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def scrape_main_table():\n",
    "    response = requests.get(SPELLS_URL, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find(\"table\", class_=\"wiki-content-table\")\n",
    "    rows = table.find_all(\"tr\")[1:]\n",
    "\n",
    "    spells = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) < 8:\n",
    "            continue\n",
    "        name_tag = cols[1].find(\"a\")\n",
    "        name = name_tag.text.strip()\n",
    "        url = BASE_URL + name_tag['href']\n",
    "        spells.append({\n",
    "            \"name\": name,\n",
    "            \"url\": url,\n",
    "            \"uses\": cols[2].text.strip(),\n",
    "            \"slots\": cols[4].text.strip(),\n",
    "            \"short_description\": cols[5].text.strip(),\n",
    "            \"location\": cols[6].get_text(separator=\" / \", strip=True),\n",
    "            \"affinity\": cols[7].text.strip()\n",
    "        })\n",
    "    return spells\n",
    "\n",
    "def scrape_spell_details(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        content_div = soup.find(\"div\", {\"id\": \"page-content\"})\n",
    "\n",
    "        # In-Game Description\n",
    "        desc_header = content_div.find(\"h2\", string=lambda s: s and \"In-Game Description\" in s)\n",
    "        in_game_description = \"\"\n",
    "        if desc_header:\n",
    "            for sibling in desc_header.find_next_siblings():\n",
    "                if sibling.name == \"p\":\n",
    "                    in_game_description += sibling.get_text(separator=\" \", strip=True) + \" \"\n",
    "                elif sibling.name == \"h2\":\n",
    "                    break\n",
    "            in_game_description = in_game_description.strip()\n",
    "\n",
    "        # Availability\n",
    "        availability_header = content_div.find(\"h2\", string=lambda s: s and \"Availability\" in s)\n",
    "        availability = []\n",
    "        if availability_header:\n",
    "            ul = availability_header.find_next_sibling(\"ul\")\n",
    "            if ul:\n",
    "                availability = [li.get_text(separator=\" \", strip=True) for li in ul.find_all(\"li\", recursive=False)]\n",
    "\n",
    "        return {\n",
    "            \"in_game_description\": in_game_description,\n",
    "            \"availability\": availability\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return {\n",
    "            \"in_game_description\": None,\n",
    "            \"availability\": None\n",
    "        }\n",
    "\n",
    "# Run the full scraping process\n",
    "spells2 = scrape_main_table()\n",
    "\n",
    "for spell in spells2:\n",
    "    print(f\"Scraping: {spell['name']}\")\n",
    "    details = scrape_spell_details(spell['url'])\n",
    "    spell[\"in_game_description\"] = details[\"in_game_description\"]\n",
    "    spell[\"availability\"] = details[\"availability\"]\n",
    "    time.sleep(1)  # polite delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"dark_souls_miracles_full.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(spells, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
